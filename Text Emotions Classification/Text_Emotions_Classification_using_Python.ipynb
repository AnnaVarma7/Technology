{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text Emotions Classification using Python**"
      ],
      "metadata": {
        "id": "JabU-4xnlNGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text emotions classification is the problem of assigning emotion to a text by understanding the context and the emotion behind the text. One real-world example is the keyboard of an iPhone that recommends the most relevant emoji by understanding the text.\n",
        "\n",
        "Text emotions classification is the problem of natural language processing and text classification. Here we need to train a text classification model to classify the emotion of a text."
      ],
      "metadata": {
        "id": "y1zCX3ITlSO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujdQ8Xn0lnqY",
        "outputId": "c2268e76-f99b-4e87-9a15-3f70dcbd2893"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ste_64-qlLrI",
        "outputId": "b09bacb7-0fba-408a-c607-98fd280af2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text Emotions\n",
            "0  i can go from feeling so hopeless to so damned...  sadness\n",
            "1   im grabbing a minute to post i feel greedy wrong    anger\n",
            "2  i am ever feeling nostalgic about the fireplac...     love\n",
            "3                               i am feeling grouchy    anger\n",
            "4  ive been feeling a little burdened lately wasn...  sadness\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow\n",
        "# Change the import statement below\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/train.txt\", sep=';')\n",
        "data.columns = [\"Text\", \"Emotions\"]\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As this is a problem of natural language processing, I’ll start by tokenizing the data:"
      ],
      "metadata": {
        "id": "7pQxMh3xmI97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data[\"Text\"].tolist()\n",
        "labels = data[\"Emotions\"].tolist()\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)"
      ],
      "metadata": {
        "id": "0Nw5aLzSmJfZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to pad the sequences to the same length to feed them into a neural network. Here’s how we can pad the sequences of the texts to have the same length:"
      ],
      "metadata": {
        "id": "sge2G7iamNvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)"
      ],
      "metadata": {
        "id": "aSRQ17IzmOKr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I’ll use the label encoder method to convert the classes from strings to a numerical representation:"
      ],
      "metadata": {
        "id": "vxQ2SwkWmRy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the string labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "UEa4_EUNmUKH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now going to One-hot encode the labels. One hot encoding refers to the transformation of categorical labels into a binary representation where each label is represented as a vector of all zeros except a single 1. This is necessary because machine learning algorithms work with numerical data. So here is how we can One-hot encode the labels:"
      ],
      "metadata": {
        "id": "LZenF2YKmWwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "one_hot_labels = keras.utils.to_categorical(labels)"
      ],
      "metadata": {
        "id": "WuWZH5UWmXh3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Emotions Classification Model**\n",
        "Now we will split the data into training and test sets:"
      ],
      "metadata": {
        "id": "Cd8CgSxvma6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(padded_sequences,\n",
        "                                                one_hot_labels,\n",
        "                                                test_size=0.2)"
      ],
      "metadata": {
        "id": "n3samslamcRl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s define a neural network architecture for our classification problem and use it to train a model to classify emotions:"
      ],
      "metadata": {
        "id": "pp04xOT2mgDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
        "                    output_dim=128, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation=\"relu\"))\n",
        "model.add(Dense(units=len(one_hot_labels[0]), activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(xtrain, ytrain, epochs=10, batch_size=32, validation_data=(xtest, ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6W-Sfffmgo3",
        "outputId": "f4120785-556e-43ae-a03e-2cb857eb7392"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.3938 - loss: 1.5195 - val_accuracy: 0.7019 - val_loss: 0.8854\n",
            "Epoch 2/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.8594 - loss: 0.4611 - val_accuracy: 0.8300 - val_loss: 0.5319\n",
            "Epoch 3/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.9830 - loss: 0.0707 - val_accuracy: 0.8206 - val_loss: 0.6217\n",
            "Epoch 4/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - accuracy: 0.9953 - loss: 0.0273 - val_accuracy: 0.8253 - val_loss: 0.6030\n",
            "Epoch 5/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.9980 - loss: 0.0122 - val_accuracy: 0.8291 - val_loss: 0.6253\n",
            "Epoch 6/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0106 - val_accuracy: 0.8272 - val_loss: 0.6695\n",
            "Epoch 7/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9989 - loss: 0.0085 - val_accuracy: 0.8259 - val_loss: 0.6885\n",
            "Epoch 8/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9970 - loss: 0.0116 - val_accuracy: 0.8241 - val_loss: 0.7156\n",
            "Epoch 9/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 36ms/step - accuracy: 0.9980 - loss: 0.0088 - val_accuracy: 0.8203 - val_loss: 0.7869\n",
            "Epoch 10/10\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - accuracy: 0.9978 - loss: 0.0088 - val_accuracy: 0.8288 - val_loss: 0.7222\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7efdae7360d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s take a sentence as an input text and see how the model performs:"
      ],
      "metadata": {
        "id": "nZC0p_MZnP9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"She didn't come today because she lost her dog yestertay!\"\n",
        "\n",
        "# Preprocess the input text\n",
        "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
        "padded_input_sequence = pad_sequences(input_sequence, maxlen=max_length)\n",
        "prediction = model.predict(padded_input_sequence)\n",
        "predicted_label = label_encoder.inverse_transform([np.argmax(prediction[0])])\n",
        "print(predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1Ab9JYynQdR",
        "outputId": "d0781048-33a4-4d55-d27d-0d41a9a84c61"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "['sadness']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this is how you can use Machine Learning for the task of text emotion classification using the Python programming language."
      ],
      "metadata": {
        "id": "NwwYu9P6nUjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "Text emotion classification is the problem of assigning emotion to a text by understanding the context and the emotion behind the text. One real-world example is the keyboard of an iPhone that recommends the most relevant emoji by understanding the text"
      ],
      "metadata": {
        "id": "_KJfduasnXHj"
      }
    }
  ]
}